[build]
build_dir = "./_site"
templates_dir = "./templates"
static_dir = "./static"

[overview]
name = "Greg Pauloski"
titles = ["Computer Scientist", "Software Engineer"]
headshot = "images/headshot.jpg"
contacts = [
    { name = "email", link = "mailto:jgpauloski@uchicago.edu" },
    { name = "github", link = "https://github.com/gpauloski" },
    { name = "linkedin", link = "https://www.linkedin.com/in/gregorypauloski/" },
    { name = "scholar", link = "https://scholar.google.com/citations?user=rek2K4EAAAAJ&hl=en" },
]
analytics = "G-RP37QLH20F"
source = "https://github.com/gpauloski/gpauloski.github.io/"
text = """
Hello there!
I am a fifth-year Ph.D. student in Computer Science at the <a href="https://cs.uchicago.edu/" target="_blank">University of Chicago</a> interested in high-performance computing, distributed systems, and deep learning frameworks.
I am a member of <a href="https://labs.globus.org" target="_blank">Globus Labs</a> where I am co-advised by <a href="https://cs.uchicago.edu/people/ian-foster/" target="_blank">Ian Foster</a> and <a href="https://kylechard.com/" target="_blank">Kyle Chard</a>.
I completed my Bachelors in Computer Science at the <a href="https://cs.utexas.edu/" target="_blank">University of Texas at Austin</a> and previously worked at Apple, Google, and the Texas Advanced Computing Center.
<br><br>
ðŸŽ‰ <b>I am on the job market!</b> Seeking full-time opportunities starting Summer 2025.
"""

[research]
sections = [
    { name = "Distributed Systems", text = "We are designing new programming paradigms which decouple communication from application design to enable multiple data movement methods depending on <i>where</i> data are moved, <i>what</i> are moved, or <i>when</i> they are moved. We are using these paradigms to build scalable scientific workflows, federated function-as-a-service platforms, and agents/actors frameworks." },
    { name = "Scalable Deep Learning", text = "We are exploring new techniques for improving deep learning training time and scalability by (1) exploiting scalable algorithms for second-order information approximation; (2) developing methods for adapting to different computer hardware by tuning computation and communication to maximize training speed; (3) exploring compression techniques to reduce communication overheads; and (4) enabling complex, hierarchical federated learning across diverse ecosystems of hardware." },
    { name = "AI for Science", text = "We are (1) training large (billion+ parameter) transformer-based language models on broad scientific literature to automate knowledge extraction; (2) developing frameworks for coupling AI and simulations on exascale supercomputers; and (3) building innovative and large-scale solutions to scientific challenges in genome evolution, next-generation battery design, and carbon capture."},
]

[projects]
github = "https://github.com/gpauloski/"
links = [
    { name = "ProxyStore", link = "https://github.com/proxystore/proxystore", description = "Pass-by-reference semantics for distributed Python applications" },
    { name = "K-FAC", link = "https://github.com/gpauloski/kfac-pytorch", description = "Distributed PyTorch K-FAC gradient preconditioner" },
    { name = "TaPS", link = "https://github.com/proxystore/taps", description = "Benchmarking suite for distributed/parallel task executors" },
    { name = "LLM Training", link = "https://github.com/gpauloski/llm-pytorch", description = "Tools and scripts for large language model training" },
    { name = "Colmena", link = "https://github.com/exalearn/colmena", description = "Steering large campaigns of simulations on HPC with AI" },
    { name = "3pseatBot", link = "https://github.com/gpauloski/3pseatBot", description = "A hobby Discord bot" },
]

[publications]
bibtex = "publications/pauloski.bib"
publications_dir = "./config/publications"

[presentations]
presentations_dir = "./config/presentations"

[theses]
theses_dir = "./config/theses"
