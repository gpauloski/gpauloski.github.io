{
    "title": "Deep Neural Network Training With Distributed K-FAC",
    "authors": [
        "J. Gregory Pauloski",
        "Lei Huang",
        "Weijia Xu",
        "Kyle Chard",
        "Ian Foster",
        "Zhao Zhang"
    ],
    "venue": "TPDS 2022",
    "tldr": "We extend our SC 2020 paper to evaluate the convergence and scaling properties of our K-FAC gradient preconditioner, for image classification, object detection, and language modeling applications. In all applications, our implementation converges to baseline performance targets in 9â€”25% less time than the standard first-order optimizers on GPU clusters across a variety of scales.",
    "paper": "publications/pauloski2022kfac-preprint.pdf",
    "bibtex": "pauloski2022kfac",
    "code": "https://github.com/gpauloski/kfac-pytorch",
    "website": null,
    "poster": null,
    "slides": null,
    "publisher": "https://ieeexplore.ieee.org/abstract/document/9739867",
    "year": 2022,
    "month": 3,
    "selected": true,
    "category": "ml"
}
