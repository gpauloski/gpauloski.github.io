---
layout: default
---

## About Me

<img class="profile-picture" src="static/headshot.jpg">

Hello there.
I am a first-year Ph.D. student in Computer Science at the University of Chicago.
I work with Dr. Ian Foster and Dr. Kyle Chard as a part of [Globus Labs](https://labs.globus.org/).
I recently completed my Bachelors in Computer Science at the University of Texas at Austin where I worked at the Texas Advanced Computing Center.

Check out my recent projects on [GitHub](https://github.com/gpauloski).
You can contact me at jgpauloski (at) uchicago (dot) edu.

## Research Interest

My interest lie at the intersection of high-performance computing and machine learning.
In particular, my research is focused on systems for enabling efficient and scalable machine learning training in large, distributed environments.
I am also interested in various optimization methods that can enable large-batch training.

## Projects

- **Distributed K-FAC Preconditioner** \[[Paper 1](https://arxiv.org/pdf/2007.00784)\] \[[Paper 2](https://arxiv.org/abs/2107.01739)\] \[[Code](https://github.com/gpauloski/kfac_pytorch)\]

- **Colmena** \[[Code](https://github.com/exalearn/colmena)\] \[[Paper](https://arxiv.org/abs/2110.02827)\]

- **ProxyStore** \[[Code](https://github.com/gpauloski/ProxyStore)\]

- **3pseatBot** \[[Code](https://github.com/gpauloski/3pseatBot)\]

- **Distributed Deep Learning for Image Segmentation** \[[Poster](https://gregpauloski.com/static/taccster_poster.pdf)\]

- See more of my latest projects on my [GitHub](https://github.com/gpauloski).

## Publications

- **J. Gregory Pauloski**, Qi Huang, Lei Huang, Shivaram Venkataraman, Kyle Chard, Ian Foster, and Zhao Zhang. 2021. [KAISA: An Adaptive Second-order Optimizer Framework for Deep Neural Networks](https://arxiv.org/abs/2107.01739). To be published in the proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC '21). \[[Code](https://github.com/gpauloski/kfac_pytorch)\]
- Ward, L., Sivaraman, G., **Pauloski, J. G.**, Babuji, Y., Chard, R., Dandu, N., Redfern, P. C., Assary, R. S., Chard, K., Curtiss, L. A., Thakur, R., Foster, I. (2021, November).
[Colmena: Scalable Machine-Learning-Based Steering of Ensemble Simulations for High Performance Computing.](https://arxiv.org/abs/2110.02827) 
Accepted to the Machine Learning in HPC Environments Workshop.
- Hong Z, **Pauloski JG**, Ward L, Chard K, Blaiszik B and Foster I (2021) [Models and Processes to Extract Drug-like Molecules From Natural Language Text](https://www.frontiersin.org/articles/10.3389/fmolb.2021.636077/full). Front. Mol. Biosci. 8:636077. doi: 10.3389/fmolb.2021.636077
- **J. Gregory Pauloski**, Zhao Zhang, Lei Huang, Weijia Xu, and Ian T. Foster. 2020. [Convolutional neural network training with distributed K-FAC](https://dl.acm.org/doi/10.5555/3433701.3433826). In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC '20). IEEE Press, Article 94, 1â€“14. \[[Code](https://github.com/gpauloski/kfac_pytorch)\]
- Z. Zhang, L. Huang, **J. G. Pauloski** and I. T. Foster, "[Efficient I/O for Neural Network Training with Compressed Data](https://ieeexplore.ieee.org/abstract/document/9139800)," 2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS), New Orleans, LA, USA, 2020, pp. 409-418, doi: 10.1109/IPDPS47924.2020.00050.
- Z. Zhang, L. Huang, **J. G. Pauloski** and I. Foster, "[Aggregating Local Storage for Scalable Deep Learning I/O](https://ieeexplore.ieee.org/document/8945112)," 2019 IEEE/ACM Third Workshop on Deep Learning on Supercomputers (DLS), Denver, CO, USA, 2019, pp. 69-75, doi: 10.1109/DLS49591.2019.00014.
- Gates E., **Pauloski J. G.**, Schellingerhout D., Fuentes D. (2019) [Glioma Segmentation and a Simple Accurate Model for Overall Survival Prediction](https://doi.org/10.1007/978-3-030-11726-9_42). In: Crimi A., Bakas S., Kuijf H., Keyvan F., Reyes M., van Walsum T. (eds) Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. BrainLes 2018. Lecture Notes in Computer Science, vol 11384. Springer, Cham.

## Presentations

- **Pauloski, J. G.** (2020, November). Convolutional Neural Network Training with Distributed K-FAC. International Conference for High Performance Computing, Networking, Storage and Analysis (SC20), Atlanta, Georgia.
- **Pauloski, J. G.** (2018, September). [Optimizing Deep Learning Methods for Image Segmentation with Distributed Training](https://gregpauloski.com/static/taccster_poster.pdf). Poster presented at the TACC Symposium for Texas Researchers, Austin, TX.
